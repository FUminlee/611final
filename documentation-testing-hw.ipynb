{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "19c41f88",
      "metadata": {
        "id": "19c41f88"
      },
      "source": [
        "# Homework: Documenting Your Code + Testing Your Code\n",
        "\n",
        "## Problem 1 - Write docstrings\n",
        "\n",
        "The following functions are missing docstrings. Write Google-style docstrings for each function, including `Args`, `Returns`, and `Raises` sections where appropriate. Make sure to document default values and explain what each parameter means."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "2cacdf2c",
      "metadata": {
        "id": "2cacdf2c"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def normalize(data, method=\"zscore\"):\n",
        "    \"\"\"\n",
        "    Normalize numerical data using a specified method.\n",
        "\n",
        "    Args:\n",
        "        data (array-like): Input numerical data to be normalized.\n",
        "        method (str, optional): Normalization method to use.\n",
        "            - \"zscore\": Standard score normalization (default).\n",
        "            - \"minmax\": Min-max normalization.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Normalized data array.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If an unsupported normalization method is provided.\n",
        "    \"\"\"\n",
        "    if method == \"zscore\":\n",
        "        return (data - np.mean(data)) / np.std(data)\n",
        "    elif method == \"minmax\":\n",
        "        return (data - np.min(data)) / (np.max(data) - np.min(data))\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown method: {method}\")\n",
        "\n",
        "\n",
        "def weighted_mean(values, weights=None):\n",
        "    \"\"\"\n",
        "    Compute the weighted mean of values.\n",
        "\n",
        "    Args:\n",
        "        values (array-like): Numerical values.\n",
        "        weights (array-like, optional): Weights corresponding to each value.\n",
        "            If None, the simple arithmetic mean is returned.\n",
        "\n",
        "    Returns:\n",
        "        float: Weighted mean of the values.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If values and weights have different lengths.\n",
        "    \"\"\"\n",
        "\n",
        "    if weights is None:\n",
        "        return np.mean(values)\n",
        "    if len(values) != len(weights):\n",
        "        raise ValueError(\"values and weights must have the same length\")\n",
        "    return np.sum(values * weights) / np.sum(weights)\n",
        "\n",
        "\n",
        "def remove_outliers(data, threshold=3.0):\n",
        "    \"\"\"\n",
        "    Remove outliers from data based on a z-score threshold.\n",
        "\n",
        "    Args:\n",
        "        data (array-like): Input numerical data.\n",
        "        threshold (float, optional): Number of standard deviations from the mean\n",
        "            beyond which a data point is considered an outlier. Default is 3.0.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Data with outliers removed.\n",
        "    \"\"\"\n",
        "\n",
        "    mean = np.mean(data)\n",
        "    std = np.std(data)\n",
        "    mask = np.abs(data - mean) <= threshold * std\n",
        "    return data[mask]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f16fb210",
      "metadata": {
        "id": "f16fb210"
      },
      "source": [
        "## Problem 2 - Add type hints\n",
        "\n",
        "The following functions have incomplete or missing type hints. Add appropriate type hints for all parameters and return values. Use `|` syntax for union types where a parameter can accept multiple types or return `None`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e458a748",
      "metadata": {
        "id": "e458a748"
      },
      "outputs": [],
      "source": [
        "from typing import Iterable, List, Optional, Dict, Union\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def clip_values(\n",
        "    arr: np.ndarray,\n",
        "    lower: float,\n",
        "    upper: float\n",
        ") -> np.ndarray:\n",
        "    \"\"\"Clip array values to be within [lower, upper] range.\"\"\"\n",
        "    return np.clip(arr, lower, upper)\n",
        "\n",
        "\n",
        "\n",
        "def find_peaks(\n",
        "    data: Iterable[float],\n",
        "    min_height: Optional[float] = None\n",
        ") -> Optional[List[int]]:\n",
        "    \"\"\"\n",
        "    Find indices where values are local maxima above min_height.\n",
        "    Returns None if no peaks are found.\n",
        "    \"\"\"\n",
        "    peaks = []\n",
        "    for i in range(1, len(data) - 1):\n",
        "        if data[i] > data[i - 1] and data[i] > data[i + 1]:\n",
        "            if min_height is None or data[i] >= min_height:\n",
        "                peaks.append(i)\n",
        "    if len(peaks) == 0:\n",
        "        return None\n",
        "    return peaks\n",
        "\n",
        "\n",
        "def summarize(\n",
        "    data: Iterable[float],\n",
        "    stats: List[str]\n",
        ") -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Calculate summary statistics for data.\n",
        "    Args:\n",
        "        data: Input array of numeric values.\n",
        "        stats: List of statistic names to compute.\n",
        "            Valid options: \"mean\", \"median\", \"std\", \"min\", \"max\"\n",
        "\n",
        "    Returns:\n",
        "        Dictionary mapping statistic names to computed values.\n",
        "    \"\"\"\n",
        "    result = {}\n",
        "    for stat in stats:\n",
        "        if stat == \"mean\": result[stat] = np.mean(data)\n",
        "        elif stat == \"median\":\n",
        "            result[stat] = np.median(data)\n",
        "        elif stat == \"std\":\n",
        "            result[stat] = np.std(data)\n",
        "        elif stat == \"min\":\n",
        "            result[stat] = np.min(data)\n",
        "        elif stat == \"max\":\n",
        "            result[stat] = np.max(data)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b66a6400",
      "metadata": {
        "id": "b66a6400"
      },
      "source": [
        "## Problem 3: Identifying Test Types\n",
        "\n",
        "For each scenario below, identify whether the test being described is a **unit test**, **integration test**, or **regression test**. Briefly explain your reasoning.\n",
        "\n",
        "**(a)** You write a test that verifies `calculate_variance()` returns 0 for the input `[3.0, 3.0, 3.0]`.\n",
        "\n",
        "Unit test\n",
        "\n",
        "**(b)** After discovering that `fit_model()` crashes when given a dataset with a single row, you fix the bug and add a test with a one-row input.\n",
        "\n",
        "Regression test\n",
        "\n",
        "**(c)** You write a test that loads data from a CSV file, passes it through `clean_data()`, fits a model with `fit_linear_regression()`, and verifies the model's R-squared value is within an expected range.\n",
        "\n",
        "Integration test\n",
        "\n",
        "**(d)** A user reports that `normalize()` returns incorrect values when all input values are negative. After fixing the issue, you add a test with input `[-5.0, -3.0, -1.0]`.\n",
        "\n",
        "Regression test\n",
        "\n",
        "## Problem 4: Code Review - What's Wrong with These Tests?\n",
        "\n",
        "Review the following test code and identify at least **four** problems with the test design or implementation. Explain why each is problematic and suggest how to fix it.\n",
        "\n",
        "1. Tests NumPy instead of user code\n",
        "\n",
        "assert np.mean(data) == 30\n",
        "\n",
        "Fix: test your wrapper / application logic instead.\n",
        "\n",
        "2. Weak assertions\n",
        "\n",
        "assert np.std(data) > 0\n",
        "\n",
        "This will pass for almost any non-constant data.\n",
        "\n",
        "Fix: assert np.isclose(np.std(data), expected_value)\n",
        "\n",
        "3. Floating-point equality check\n",
        "\n",
        "assert corr == 1.0\n",
        "\n",
        "Floating-point math is not exact.\n",
        "\n",
        "Fix: assert np.isclose(corr, 1.0)\n",
        "\n",
        "4. Shared global state between tests\n",
        "\n",
        "results = []\n",
        "\n",
        "Test order matters → flaky tests.\n",
        "\n",
        "Fix: use fixtures or reset state per test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb0f31e7",
      "metadata": {
        "id": "bb0f31e7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def test_all_statistics():\n",
        "    data = [10, 20, 30, 40, 50]\n",
        "\n",
        "    # Test mean\n",
        "    assert np.mean(data) == 30\n",
        "\n",
        "    # Test median\n",
        "    assert np.median(data) == 30\n",
        "\n",
        "    # Test standard deviation\n",
        "    assert np.std(data) > 0\n",
        "\n",
        "    # Test min and max\n",
        "    assert np.min(data) == 10\n",
        "    assert np.max(data) == 50\n",
        "\n",
        "    # Test sum\n",
        "    assert np.sum(data) == 150\n",
        "\n",
        "def verify_variance_positive(arr):\n",
        "    var = np.var(arr)\n",
        "    assert var >= 0\n",
        "\n",
        "def test_correlation():\n",
        "    x = np.array([1.0, 2.0, 3.0])\n",
        "    y = np.array([2.0, 4.0, 6.0])\n",
        "    corr = np.corrcoef(x, y)[0, 1]\n",
        "    assert corr == 1.0\n",
        "\n",
        "results = []\n",
        "\n",
        "def test_append_result():\n",
        "    global results\n",
        "    results.append(42)\n",
        "    assert 42 in results\n",
        "\n",
        "def test_check_results():\n",
        "    assert len(results) == 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3030fab2",
      "metadata": {
        "id": "3030fab2"
      },
      "source": [
        "## Problem 5: The Flaky Test\n",
        "\n",
        "Your colleague wrote the following test for a bootstrap confidence interval function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "235ca02a",
      "metadata": {
        "id": "235ca02a"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def bootstrap_ci(data, confidence=0.95, n_bootstrap=1000):\n",
        "    \"\"\"Compute bootstrap confidence interval for the mean.\"\"\"\n",
        "    means = []\n",
        "    n = len(data)\n",
        "    for _ in range(n_bootstrap):\n",
        "        sample = np.random.choice(data, size=n, replace=True)\n",
        "        means.append(np.mean(sample))\n",
        "\n",
        "    alpha = 1 - confidence\n",
        "    lower = np.percentile(means, 100 * alpha / 2)\n",
        "    upper = np.percentile(means, 100 * (1 - alpha / 2))\n",
        "    return lower, upper\n",
        "\n",
        "def test_bootstrap_ci_contains_true_mean():\n",
        "    data = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
        "    true_mean = 5.5\n",
        "    lower, upper = bootstrap_ci(data)\n",
        "    assert lower < true_mean < upper"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "860f28d3",
      "metadata": {
        "id": "860f28d3"
      },
      "source": [
        "**(a)** The test passes most of the time but occasionally fails. Explain why this test is \"flaky\" (non-deterministic).\n",
        "\n",
        "(a)\n",
        "Bootstrap uses random sampling\n",
        "No fixed random seed\n",
        "CI does not guarantee containing the true mean every run\n",
        "\n",
        "**(b)** Your colleague argues: \"The test is correct because a 95% confidence interval should contain the true mean 95% of the time, so occasional failures are expected.\" Is this a good argument for keeping the test as-is? Why or why not?\n",
        "\n",
        "No\n",
        "Statistical guarantees apply across repeated experiments, not to a single test run\n",
        "Unit tests must be deterministic\n",
        "\n",
        "**(c)** Rewrite the test to be deterministic and reliable while still meaningfully testing the `bootstrap_ci` function. Your solution should: ensure reproducible results and verify that the confidence interval has reasonable properties.\n",
        "\n",
        "**(d)** Propose an alternative testing strategy that could verify the 95% coverage property without making the test flaky. You don't need to implement it, but describe the approach.\n",
        "\n",
        "Monte Carlo coverage test (non-flaky):\n",
        "Run bootstrap CI many times (e.g., 1000 simulations)\n",
        "Count how often the CI contains the true mean\n",
        "Assert coverage is within tolerance (e.g., 93%–97%)\n",
        "This is a statistical validation test, not a unit test, and should be run separately (e.g., nightly or CI “slow tests”)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#(c)\n",
        "def test_bootstrap_ci_properties():\n",
        "    np.random.seed(0)\n",
        "\n",
        "    data = np.array([1,2,3,4,5,6,7,8,9,10])\n",
        "    lower, upper = bootstrap_ci(data, n_bootstrap=5000)\n",
        "\n",
        "    mean = np.mean(data)\n",
        "\n",
        "    assert lower < upper\n",
        "    assert lower <= mean <= upper\n"
      ],
      "metadata": {
        "id": "Defosv3UcEHw"
      },
      "id": "Defosv3UcEHw",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4wiQ2SxacIEC"
      },
      "id": "4wiQ2SxacIEC",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}